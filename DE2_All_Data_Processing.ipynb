{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-06-26\n",
    "\n",
    "In this Notebook I will be creating a general script to take in all the .cdf files for the neutral and ion spectrometer DE2 instruments (Neutral Atmospheric Composition Spectrometer (NACS) and Retarding Potential Analyzer RPA, respectively) and then produce a dataframe that contains measures for the mass density. \n",
    "\n",
    "This dataframe can then be exported to .csv and compared to the RMIT/SERC model in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cdflib\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob all the .cdf files that have the 2 sec measurements:\n",
    "NACS_cdf_list = list(Path.cwd().glob('neutral_gas_nacs/**/*.cdf'))\n",
    "RPA_cdf_list = list(Path.cwd().glob('plasma_rpa/ion2s_cdaweb/**/*.cdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NACS file list contains 539, the RPA file list contains 450.\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the two lists:\n",
    "print(f'The NACS file list contains {len(NACS_cdf_list)}, the RPA file list contains {len(RPA_cdf_list)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to find the days that overlap and create a list of 'good' files to run\n",
    "NACS_cdf_good = []\n",
    "RPA_cdf_good = []\n",
    "for n_i in range(0,len(NACS_cdf_list)):\n",
    "    for r_i in range(0,len(RPA_cdf_list)):\n",
    "        if str(NACS_cdf_list[n_i])[-16:] == str(RPA_cdf_list[r_i])[-16:]:\n",
    "            NACS_cdf_good.append(NACS_cdf_list[n_i])\n",
    "            RPA_cdf_good.append(RPA_cdf_list[r_i])\n",
    "            break\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for making the dataframes\n",
    "def reshape_fn(arr_list):\n",
    "    reshaped_list = []\n",
    "    for arr in arr_list:\n",
    "        reshaped_list.append(np.reshape(arr,(len(arr),1)))\n",
    "    return reshaped_list\n",
    "\n",
    "def df_maker(path):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    vrs = cdf.cdf_info()['zVariables']\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    return df\n",
    "\n",
    "#df_nacs = pd.DataFrame()\n",
    "#df_rpa = pd.DataFrame()\n",
    "\n",
    "#for path in NACS_cdf_good:\n",
    "#    df_nacs = df_nacs.append(df_maker(path),ignore_index=True)\n",
    "\n",
    "#for path in RPA_cdf_good:\n",
    "#    df_rpa = df_rpa.append(df_maker(path),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing up the functions above helped quite a bit in processing the data faster, but still need to write up additional functions to do the processing for each set of NACS-RPA files before it is appended to a master dataframe with both instruments' measurements present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-06-27 / 2019-06-28\n",
    "\n",
    "I'll try to incorporate the processing of data to the final mass density measurements before creating the data frame and saving to .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the dataframes for the given day, I need to calculate the densities and store in one dataframe. \n",
    "# This is done in two functions below:\n",
    "\n",
    "def df_make(path, vrs):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    # Round Epoch times to the nearest second:\n",
    "    epoch_round = lambda x: round(x/1000)*1000\n",
    "    df['Epoch'] = df['Epoch'].apply(epoch_round)\n",
    "    return df\n",
    "\n",
    "def rpa_nacs_comb_day(path_rpa, path_nacs, vrs_rpa, vrs_nacs):\n",
    "    \n",
    "    # Make dfs:\n",
    "    df_nacs = df_make(path_rpa, vrs_rpa)\n",
    "    df_rpa = df_make(path_nacs, vrs_nacs)\n",
    "    \n",
    "    # Find indexes of same times:\n",
    "    rpa_nacs_idxs = []\n",
    "    for idx1,ep1 in enumerate(df_rpa['Epoch']):\n",
    "        for idx2,ep2 in enumerate(df_nacs['Epoch']):\n",
    "            if (ep1 == ep2):# and (ep1 != ep0):\n",
    "                rpa_nacs_idxs.append((idx1,idx2))\n",
    "                #ep0 = ep2\n",
    "                idx0 = idx2\n",
    "                break\n",
    "    # Create dataframes to store 16-sec window averages\n",
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    # Search through the list of index tuples and find only those that have the right time spans (16 sec increments)\n",
    "    pi1, pi2 = rpa_nacs_idxs[0]\n",
    "    idx_range = range(8,len(rpa_nacs_idxs),8)\n",
    "            \n",
    "    # Run through the results to see whether they meet the 16-sec window criterion, calculate the mean if so:\n",
    "    for i,v in enumerate(rpa_nacs_idxs[8::8]):\n",
    "        i1, i2 = v\n",
    "        if (i1 - pi1 == 16) and (i2 - pi2 == 16):\n",
    "            r_means = {}\n",
    "            n_means = {}\n",
    "            for var in df_rpa.columns:\n",
    "                r_means[var] = df_rpa[rpa_nacs_idxs[(i-1)*8][0]:rpa_nacs_idxs[i*8][0]][var].mean()\n",
    "            for var in df_nacs.columns:\n",
    "                n_means[var] = df_nacs[rpa_nacs_idxs[(i-1)*8][1]:rpa_nacs_idxs[i*8][1]][var].mean()\n",
    "            RPA_df = RPA_df.append(r_means, ignore_index=True)\n",
    "            NACS_df = NACS_df.append(n_means, ignore_index=True)\n",
    "        pi1, pi2 = i1, i2    \n",
    "    \n",
    "        #   if i == 0:\n",
    "        #   if (rpa_nacs_idxs[8][0] - rpa_nacs_idxs[0][0] == 16) and (rpa_nacs_idxs[8][1] - rpa_nacs_idxs[0][1] == 16):\n",
    "        #       r_means = {}\n",
    "        #       n_means = {}\n",
    "        #       for var in df_rpa.columns:\n",
    "        #           r_means[var] = df_rpa[rpa_nacs_idxs[0][0]:rpa_nacs_idxs[8][0]][var].mean()\n",
    "        #       for var in df_nacs.columns:\n",
    "        #           n_means[var] = df_nacs[rpa_nacs_idxs[0][1]:rpa_nacs_idxs[8][1]][var].mean()\n",
    "        #       RPA_df = RPA_df.append(r_means, ignore_index=True)\n",
    "        #       NACS_df = NACS_df.append(n_means, ignore_index=True)\n",
    "        #else:\n",
    "    \n",
    "    \n",
    "    # One atomic mass unit in kilograms\n",
    "    amukg = 1.66054e-27\n",
    "\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "    # Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "    tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "    for idx in range(0,len(NACS_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "            den = NACS_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "        tot_den_nacs[idx] = tot_den\n",
    "    try:\n",
    "        NACS_df['total_mass_den'] = tot_den_nacs\n",
    "    except:\n",
    "        \n",
    "        print(tot_den_nacs)\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "    # Total density of ions in kg.m^-3 for PRA instrument\n",
    "    tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "    for idx in range(0,len(RPA_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "            den = RPA_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "        tot_den_rpa[idx] = tot_den\n",
    "\n",
    "    RPA_df['total_mass_den'] = (tot_den_rpa)\n",
    "\n",
    "    pos_vars = ['Epoch']\n",
    "    for el in nacs_var_list[6:9]:\n",
    "        pos_vars.append(el)\n",
    "    pos_vars.append('total_mass_den')\n",
    "\n",
    "    df_tot_day = pd.DataFrame()\n",
    "\n",
    "    for var in pos_vars:\n",
    "        if var == 'total_mass_den':\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var])\n",
    "            df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "            df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "        else:\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var]) / 2\n",
    "\n",
    "    # Convert glat and glon to radians:\n",
    "    df_tot_day['glat'] = df_tot_day['glat'] * (np.pi/180)\n",
    "    df_tot_day['glon'] = df_tot_day['glon'] * (np.pi/180)\n",
    "\n",
    "    dat_list = []\n",
    "    for i,epoch in enumerate(df_tot_day['Epoch']):\n",
    "        if pd.isnull(epoch):\n",
    "            print(f'This value {epoch} is null. This is record number {i} in the file {path_rpa} or {path_nacs}')\n",
    "        dat_list.append(pd.to_datetime(cdflib.cdfepoch.encode(epoch), infer_datetime_format=True))\n",
    "\n",
    "    d_t = pd.DatetimeIndex(dat_list)\n",
    "    df_tot_day['datetime'] = d_t\n",
    "    df_tot_day['year'] = d_t.year\n",
    "    df_tot_day['doy'] = d_t.dayofyear\n",
    "    df_tot_day['d_hr'] = d_t.hour + d_t.minute/60 + d_t.second/3600\n",
    "    return df_tot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of the variables of interest and create an array that contains the relevant data:\n",
    "rpa_var_list = [\n",
    "    'Epoch',\n",
    "    'O',\n",
    "    'H',\n",
    "    'He',\n",
    "    'molecularIons',\n",
    "    'glat',\n",
    "    'glon',\n",
    "    'alt'\n",
    "]\n",
    "\n",
    "nacs_var_list = [\n",
    " 'Epoch',\n",
    " 'O_density',\n",
    " 'N2_density',\n",
    " 'He_density',\n",
    " 'N_density',\n",
    " 'Ar_density',\n",
    " 'alt',\n",
    " 'glat',\n",
    " 'glon',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through all files and save the daily total density values for \n",
    "\n",
    "all_var_list = [\n",
    "    'Epoch',\n",
    "    'alt',\n",
    "    'glat',\n",
    "    'glon',\n",
    "    'total_mass_den',\n",
    "    'total_neutral_den',\n",
    "    'total_ion_den',\n",
    "    'datetime',\n",
    "    'year',\n",
    "    'doy',\n",
    "    'd_hr'\n",
    "]\n",
    "\n",
    "df_all = pd.DataFrame(columns = all_var_list)\n",
    "\n",
    "#for rpa_path, nacs_path in zip(RPA_cdf_good, NACS_cdf_good):\n",
    "#    df_tot_day = rpa_nacs_comb_day(rpa_path, nacs_path, rpa_var_list, nacs_var_list)\n",
    "#    df_all.append(df_tot_day, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_path = Path(Path.cwd(),'DE2_Tot_Den_All_Data.csv')\n",
    "#df_nacs.to_csv(out_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa = df_make(RPA_cdf_good[15],rpa_var_list)\n",
    "nacs = df_make(NACS_cdf_good[15],nacs_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>O</th>\n",
       "      <th>H</th>\n",
       "      <th>He</th>\n",
       "      <th>molecularIons</th>\n",
       "      <th>glat</th>\n",
       "      <th>glon</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62535813280000</td>\n",
       "      <td>140556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.360001</td>\n",
       "      <td>126.940002</td>\n",
       "      <td>815.590027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62535813282000</td>\n",
       "      <td>140670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.240002</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>814.890015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62535813284000</td>\n",
       "      <td>30679.0</td>\n",
       "      <td>40362.0</td>\n",
       "      <td>17398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.130001</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>814.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62535813290000</td>\n",
       "      <td>145175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.770000</td>\n",
       "      <td>126.900002</td>\n",
       "      <td>812.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62535813291000</td>\n",
       "      <td>146130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.709999</td>\n",
       "      <td>126.900002</td>\n",
       "      <td>811.780029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62535813294000</td>\n",
       "      <td>146372.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.540001</td>\n",
       "      <td>126.879997</td>\n",
       "      <td>810.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62535813295000</td>\n",
       "      <td>147044.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.480000</td>\n",
       "      <td>126.879997</td>\n",
       "      <td>810.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62535813298000</td>\n",
       "      <td>146931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.299999</td>\n",
       "      <td>126.870003</td>\n",
       "      <td>809.349976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62535813299000</td>\n",
       "      <td>148248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.240002</td>\n",
       "      <td>126.860001</td>\n",
       "      <td>809.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62535813302000</td>\n",
       "      <td>148709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.070000</td>\n",
       "      <td>126.849998</td>\n",
       "      <td>807.960022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62535813303000</td>\n",
       "      <td>149091.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.009998</td>\n",
       "      <td>126.849998</td>\n",
       "      <td>807.609985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62535813306000</td>\n",
       "      <td>149622.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-31.830000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>806.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62535813307000</td>\n",
       "      <td>150349.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-31.770000</td>\n",
       "      <td>126.830002</td>\n",
       "      <td>806.219971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62535813310000</td>\n",
       "      <td>150702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-31.590000</td>\n",
       "      <td>126.820000</td>\n",
       "      <td>805.169983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62535813311000</td>\n",
       "      <td>151374.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-31.540001</td>\n",
       "      <td>126.809998</td>\n",
       "      <td>804.820007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Epoch         O        H       He  molecularIons       glat  \\\n",
       "0   62535813280000  140556.0      NaN      NaN            NaN -33.360001   \n",
       "1   62535813282000  140670.0      NaN      NaN            NaN -33.240002   \n",
       "2   62535813284000   30679.0  40362.0  17398.0            NaN -33.130001   \n",
       "3   62535813290000  145175.0      NaN      NaN            NaN -32.770000   \n",
       "4   62535813291000  146130.0      NaN      NaN            NaN -32.709999   \n",
       "5   62535813294000  146372.0      NaN      NaN            NaN -32.540001   \n",
       "6   62535813295000  147044.0      NaN      NaN            NaN -32.480000   \n",
       "7   62535813298000  146931.0      NaN      NaN            NaN -32.299999   \n",
       "8   62535813299000  148248.0      NaN      NaN            NaN -32.240002   \n",
       "9   62535813302000  148709.0      NaN      NaN            NaN -32.070000   \n",
       "10  62535813303000  149091.0      NaN      NaN            NaN -32.009998   \n",
       "11  62535813306000  149622.0      NaN      NaN            NaN -31.830000   \n",
       "12  62535813307000  150349.0      NaN      NaN            NaN -31.770000   \n",
       "13  62535813310000  150702.0      NaN      NaN            NaN -31.590000   \n",
       "14  62535813311000  151374.0      NaN      NaN            NaN -31.540001   \n",
       "\n",
       "          glon         alt  \n",
       "0   126.940002  815.590027  \n",
       "1   126.930000  814.890015  \n",
       "2   126.930000  814.200012  \n",
       "3   126.900002  812.130005  \n",
       "4   126.900002  811.780029  \n",
       "5   126.879997  810.739990  \n",
       "6   126.879997  810.400024  \n",
       "7   126.870003  809.349976  \n",
       "8   126.860001  809.010010  \n",
       "9   126.849998  807.960022  \n",
       "10  126.849998  807.609985  \n",
       "11  126.830002  806.570007  \n",
       "12  126.830002  806.219971  \n",
       "13  126.820000  805.169983  \n",
       "14  126.809998  804.820007  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpa.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>O_density</th>\n",
       "      <th>N2_density</th>\n",
       "      <th>He_density</th>\n",
       "      <th>N_density</th>\n",
       "      <th>Ar_density</th>\n",
       "      <th>alt</th>\n",
       "      <th>glat</th>\n",
       "      <th>glon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62535813172000</td>\n",
       "      <td>3364367.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851.460022</td>\n",
       "      <td>-39.630001</td>\n",
       "      <td>127.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62535813173000</td>\n",
       "      <td>3488655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851.140015</td>\n",
       "      <td>-39.580002</td>\n",
       "      <td>127.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62535813174000</td>\n",
       "      <td>3347600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.820007</td>\n",
       "      <td>-39.520000</td>\n",
       "      <td>127.370003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62535813175000</td>\n",
       "      <td>3386703.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.489990</td>\n",
       "      <td>-39.459999</td>\n",
       "      <td>127.370003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62535813180000</td>\n",
       "      <td>3394127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848.869995</td>\n",
       "      <td>-39.160000</td>\n",
       "      <td>127.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62535813181000</td>\n",
       "      <td>3449103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848.549988</td>\n",
       "      <td>-39.110001</td>\n",
       "      <td>127.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62535813182000</td>\n",
       "      <td>3438863.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848.219971</td>\n",
       "      <td>-39.049999</td>\n",
       "      <td>127.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62535813183000</td>\n",
       "      <td>3489551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.900024</td>\n",
       "      <td>-38.990002</td>\n",
       "      <td>127.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62535813188000</td>\n",
       "      <td>3526799.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.270020</td>\n",
       "      <td>-38.689999</td>\n",
       "      <td>127.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62535813189000</td>\n",
       "      <td>3459343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845.940002</td>\n",
       "      <td>-38.639999</td>\n",
       "      <td>127.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62535813190000</td>\n",
       "      <td>3504015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845.619995</td>\n",
       "      <td>-38.580002</td>\n",
       "      <td>127.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62535813191000</td>\n",
       "      <td>3499343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845.289978</td>\n",
       "      <td>-38.520000</td>\n",
       "      <td>127.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62535813196000</td>\n",
       "      <td>3671118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843.650024</td>\n",
       "      <td>-38.220001</td>\n",
       "      <td>127.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62535813197000</td>\n",
       "      <td>3617551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843.330017</td>\n",
       "      <td>-38.169998</td>\n",
       "      <td>127.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62535813198000</td>\n",
       "      <td>3576591.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>-38.110001</td>\n",
       "      <td>127.269997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Epoch  O_density  N2_density  He_density  N_density  Ar_density  \\\n",
       "0   62535813172000  3364367.0         0.0         0.0        0.0         0.0   \n",
       "1   62535813173000  3488655.0         0.0         0.0        0.0         0.0   \n",
       "2   62535813174000  3347600.0         0.0         0.0        0.0         0.0   \n",
       "3   62535813175000  3386703.0         0.0         0.0        0.0         0.0   \n",
       "4   62535813180000  3394127.0         0.0         0.0        0.0         0.0   \n",
       "5   62535813181000  3449103.0         0.0         0.0        0.0         0.0   \n",
       "6   62535813182000  3438863.0         0.0         0.0        0.0         0.0   \n",
       "7   62535813183000  3489551.0         0.0         0.0        0.0         0.0   \n",
       "8   62535813188000  3526799.0         0.0         0.0        0.0         0.0   \n",
       "9   62535813189000  3459343.0         0.0         0.0        0.0         0.0   \n",
       "10  62535813190000  3504015.0         0.0         0.0        0.0         0.0   \n",
       "11  62535813191000  3499343.0         0.0         0.0        0.0         0.0   \n",
       "12  62535813196000  3671118.0         0.0         0.0        0.0         0.0   \n",
       "13  62535813197000  3617551.0         0.0         0.0        0.0         0.0   \n",
       "14  62535813198000  3576591.0         0.0         0.0        0.0         0.0   \n",
       "\n",
       "           alt       glat        glon  \n",
       "0   851.460022 -39.630001  127.379997  \n",
       "1   851.140015 -39.580002  127.379997  \n",
       "2   850.820007 -39.520000  127.370003  \n",
       "3   850.489990 -39.459999  127.370003  \n",
       "4   848.869995 -39.160000  127.349998  \n",
       "5   848.549988 -39.110001  127.349998  \n",
       "6   848.219971 -39.049999  127.339996  \n",
       "7   847.900024 -38.990002  127.339996  \n",
       "8   846.270020 -38.689999  127.320000  \n",
       "9   845.940002 -38.639999  127.309998  \n",
       "10  845.619995 -38.580002  127.309998  \n",
       "11  845.289978 -38.520000  127.300003  \n",
       "12  843.650024 -38.220001  127.279999  \n",
       "13  843.330017 -38.169998  127.279999  \n",
       "14  843.000000 -38.110001  127.269997  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3172\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3173\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3174\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    274\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 275\u001b[1;33m                                        raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m   4164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c578ec97f14f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrpa_nacs_comb_day\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRPA_cdf_good\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNACS_cdf_good\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrpa_var_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnacs_var_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-257e57d89e3b>\u001b[0m in \u001b[0;36mrpa_nacs_comb_day\u001b[1;34m(path_rpa, path_nacs, vrs_rpa, vrs_nacs)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mtot_den_rpa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtot_den\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mRPA_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_mass_den'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtot_den_rpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mpos_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3117\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3191\u001b[0m         \"\"\"\n\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3193\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3194\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\TDI-Challenge\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3173\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3174\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3175\u001b[1;33m                 raise ValueError('Cannot set a frame with no defined index '\n\u001b[0m\u001b[0;32m   3176\u001b[0m                                  \u001b[1;34m'and a value that cannot be converted to a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3177\u001b[0m                                  'Series')\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "A = rpa_nacs_comb_day(RPA_cdf_good[400], NACS_cdf_good[400], rpa_var_list, nacs_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa = df_make(RPA_cdf_good[400],rpa_var_list)\n",
    "nacs = df_make(NACS_cdf_good[400],nacs_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rpa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa_nacs_idxs = []\n",
    "ep0 = 0\n",
    "for idx1,ep1 in enumerate(rpa['Epoch']):\n",
    "    for idx2,ep2 in enumerate(nacs['Epoch']):\n",
    "        if (ep1 == ep2) and (ep1 != ep0):\n",
    "            rpa_nacs_idxs.append((idx1,idx2))\n",
    "            ep0 = ep2\n",
    "            idx0 = idx2\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa['Epoch'][rpa_nacs_idxs[3][0]] - rpa['Epoch'][rpa_nacs_idxs[2][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the various things I have tried, it seems like the major problem here is that the alignment of times process is problematic. \n",
    "\n",
    "Rounding the times to the nearest second can create rows with the same time, if they are close enough to each other.\n",
    "\n",
    "Also, in some files the difference between records is 2 sec, in some it is 1 sec. Therefore the number of indexes forward to use when taking the 16-sec averages will differ from file to file.\n",
    "\n",
    "\n",
    "### 2019-07-01\n",
    "\n",
    "Need to write up a search algorithm to find the number of indexes between one record and one 16-sec in the future.\n",
    "\n",
    "This could be done at the start and then tested for the same number of places throughout the rest of the file. Would also need to find the next available record after a given 16-sec window is checked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_make(path, vrs):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    # Round Epoch times to the nearest second:\n",
    "    epoch_round = lambda x: round(x/1000)*1000\n",
    "    df['Epoch'] = df['Epoch'].apply(epoch_round)\n",
    "    return df\n",
    "\n",
    "def rpa_nacs_comb_day(path_rpa, path_nacs, vrs_rpa, vrs_nacs):\n",
    "    \n",
    "    # Make dfs:\n",
    "    df_nacs = df_make(path_rpa, vrs_rpa)\n",
    "    df_rpa = df_make(path_nacs, vrs_nacs)\n",
    "    \n",
    "    # Find indexes of same times:\n",
    "    rpa_nacs_idxs = []\n",
    "    for idx1,ep1 in enumerate(df_rpa['Epoch']):\n",
    "        for idx2,ep2 in enumerate(df_nacs['Epoch']):\n",
    "            if (ep1 == ep2) and (ep1 != ep0):\n",
    "                rpa_nacs_idxs.append((idx1,idx2))\n",
    "                ep0 = ep2\n",
    "                idx0 = idx2\n",
    "                break\n",
    "    # Create dataframes to store 16-sec window averages\n",
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    # Search through the list of index tuples and find only those that have the right time spans (16 sec increments)\n",
    "    for i in range(0,20):\n",
    "        if RPA_df['Epoch'][i] - RPA_df['Epoch'][0] == 16000.0:\n",
    "            \n",
    "        \n",
    "    \n",
    "    pi1, pi2 = rpa_nacs_idxs[0]\n",
    "    idx_range = range(8,len(rpa_nacs_idxs),8)\n",
    "            \n",
    "    # Run through the results to see whether they meet the 16-sec window criterion, calculate the mean if so:\n",
    "    for i,v in enumerate(rpa_nacs_idxs[8::8]):\n",
    "        i1, i2 = v\n",
    "        if (i1 - pi1 == 16) and (i2 - pi2 == 16):\n",
    "            r_means = {}\n",
    "            n_means = {}\n",
    "            for var in df_rpa.columns:\n",
    "                r_means[var] = df_rpa[rpa_nacs_idxs[(i-1)*8][0]:rpa_nacs_idxs[i*8][0]][var].mean()\n",
    "            for var in df_nacs.columns:\n",
    "                n_means[var] = df_nacs[rpa_nacs_idxs[(i-1)*8][1]:rpa_nacs_idxs[i*8][1]][var].mean()\n",
    "            RPA_df = RPA_df.append(r_means, ignore_index=True)\n",
    "            NACS_df = NACS_df.append(n_means, ignore_index=True)\n",
    "        pi1, pi2 = i1, i2    \n",
    "    \n",
    "        #   if i == 0:\n",
    "        #   if (rpa_nacs_idxs[8][0] - rpa_nacs_idxs[0][0] == 16) and (rpa_nacs_idxs[8][1] - rpa_nacs_idxs[0][1] == 16):\n",
    "        #       r_means = {}\n",
    "        #       n_means = {}\n",
    "        #       for var in df_rpa.columns:\n",
    "        #           r_means[var] = df_rpa[rpa_nacs_idxs[0][0]:rpa_nacs_idxs[8][0]][var].mean()\n",
    "        #       for var in df_nacs.columns:\n",
    "        #           n_means[var] = df_nacs[rpa_nacs_idxs[0][1]:rpa_nacs_idxs[8][1]][var].mean()\n",
    "        #       RPA_df = RPA_df.append(r_means, ignore_index=True)\n",
    "        #       NACS_df = NACS_df.append(n_means, ignore_index=True)\n",
    "        #else:\n",
    "    \n",
    "    \n",
    "    # One atomic mass unit in kilograms\n",
    "    amukg = 1.66054e-27\n",
    "\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "    # Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "    tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "    for idx in range(0,len(NACS_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "            den = NACS_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "        tot_den_nacs[idx] = tot_den\n",
    "    try:\n",
    "        NACS_df['total_mass_den'] = tot_den_nacs\n",
    "    except:\n",
    "        \n",
    "        print(tot_den_nacs)\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "    # Total density of ions in kg.m^-3 for PRA instrument\n",
    "    tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "    for idx in range(0,len(RPA_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "            den = RPA_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "        tot_den_rpa[idx] = tot_den\n",
    "\n",
    "    RPA_df['total_mass_den'] = (tot_den_rpa)\n",
    "\n",
    "    pos_vars = ['Epoch']\n",
    "    for el in nacs_var_list[6:9]:\n",
    "        pos_vars.append(el)\n",
    "    pos_vars.append('total_mass_den')\n",
    "\n",
    "    df_tot_day = pd.DataFrame()\n",
    "\n",
    "    for var in pos_vars:\n",
    "        if var == 'total_mass_den':\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var])\n",
    "            df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "            df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "        else:\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var]) / 2\n",
    "\n",
    "    # Convert glat and glon to radians:\n",
    "    df_tot_day['glat'] = df_tot_day['glat'] * (np.pi/180)\n",
    "    df_tot_day['glon'] = df_tot_day['glon'] * (np.pi/180)\n",
    "\n",
    "    dat_list = []\n",
    "    for i,epoch in enumerate(df_tot_day['Epoch']):\n",
    "        if pd.isnull(epoch):\n",
    "            print(f'This value {epoch} is null. This is record number {i} in the file {path_rpa} or {path_nacs}')\n",
    "        dat_list.append(pd.to_datetime(cdflib.cdfepoch.encode(epoch), infer_datetime_format=True))\n",
    "\n",
    "    d_t = pd.DatetimeIndex(dat_list)\n",
    "    df_tot_day['datetime'] = d_t\n",
    "    df_tot_day['year'] = d_t.year\n",
    "    df_tot_day['doy'] = d_t.dayofyear\n",
    "    df_tot_day['d_hr'] = d_t.hour + d_t.minute/60 + d_t.second/3600\n",
    "    return df_tot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly covered in DE2_Data_Analysis but the main investigation was:\n",
    "\n",
    "print(\"For the neutrals measuring instrument, NACS, the difference between the recorded measurements are as follows:\")\n",
    "for i in range(1,8):\n",
    "    print(f\"Difference between record {i} and {i-1} is {df_nacs['Epoch'][i]-df_nacs['Epoch'][i-1]}\")\n",
    "print(f\"Overall difference between record 0 and 7 is: {df_nacs['Epoch'][8]-df_nacs['Epoch'][0]}\")\n",
    "      \n",
    "for i in range(0,12):\n",
    "    print(f\"Difference between record {i} and 0 is {df_nacs['Epoch'][i] - df_nacs['Epoch'][0]} therefore and\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-07-02\n",
    "\n",
    "What I can do instead to simplify processing it is to just use all of the measurements that align to within 1 sec. That way I don't need to worry about using a 16-sec window finder. If necessary, I can average out the total mass density at the end. The table at the end will be larger than it would have been, but still smaller than keeping all the data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_make2(path, vrs):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    # Round Epoch times to the nearest second:\n",
    "    epoch_round = lambda x: round(x/1000)*1000\n",
    "    df['Epoch'] = df['Epoch'].apply(epoch_round)\n",
    "    return df\n",
    "\n",
    "def rpa_nacs_comb_day2(path_rpa, path_nacs, vrs_rpa, vrs_nacs):\n",
    "    \n",
    "    # Make dfs:\n",
    "    df_nacs = df_make2(path_rpa, vrs_rpa)\n",
    "    df_rpa = df_make2(path_nacs, vrs_nacs)\n",
    "    \n",
    "    # Create dataframes to store only aligned records\n",
    "    # Find all aligned records and add them to new data frame:\n",
    "    \n",
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    pn_ep = -5\n",
    "    for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "        #print(r_ep)\n",
    "        for n_idx,n_ep in enumerate(df_nacs['Epoch']):\n",
    "            #print(n_ep)\n",
    "            if (r_ep == n_ep) and (r_ep != pn_ep):\n",
    "                rpa_nans = 0\n",
    "                nacs_nans = 0\n",
    "                for var_r in rpa_var_list[1:5]:\n",
    "                    if np.isnan(df_rpa.iloc[r_idx][var_r]):\n",
    "                        rpa_nans += 1\n",
    "                for var_n in nacs_var_list[1:6]:\n",
    "                    if np.isnan(df_nacs.iloc[n_idx][var_n]):\n",
    "                        nacs_nans += 1                    \n",
    "                if (rpa_nans == 4) or (nacs_nans == 5):\n",
    "                    break\n",
    "                else:\n",
    "                    RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "                    NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "                    pn_ep = n_ep\n",
    "                    break\n",
    "    \n",
    "    # One atomic mass unit in kilograms\n",
    "    amukg = 1.66054e-27\n",
    "\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "    # Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "    tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "    for idx in range(0,len(NACS_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "            den = NACS_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "        tot_den_nacs[idx] = tot_den\n",
    "    try:\n",
    "        NACS_df['total_mass_den'] = tot_den_nacs\n",
    "    except:\n",
    "        print(tot_den_nacs)\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "    # Total density of ions in kg.m^-3 for PRA instrument\n",
    "    tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "    for idx in range(0,len(RPA_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "            den = RPA_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "        tot_den_rpa[idx] = tot_den\n",
    "    try:\n",
    "        RPA_df['total_mass_den'] = tot_den_rpa\n",
    "    except:\n",
    "        print(tot_den_rpa)\n",
    "        \n",
    "    pos_vars = ['Epoch']\n",
    "    for el in nacs_var_list[6:9]:\n",
    "        pos_vars.append(el)\n",
    "    pos_vars.append('total_mass_den')\n",
    "\n",
    "    df_tot_day = pd.DataFrame()\n",
    "\n",
    "    for var in pos_vars:\n",
    "        if var == 'total_mass_den':\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var])\n",
    "            df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "            df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "        else:\n",
    "            df_tot_day[var] = (RPA_df[var] + NACS_df[var]) / 2\n",
    "\n",
    "    # Convert glat and glon to radians:\n",
    "    df_tot_day['glat'] = df_tot_day['glat'] * (np.pi/180)\n",
    "    df_tot_day['glon'] = df_tot_day['glon'] * (np.pi/180)\n",
    "\n",
    "    dat_list = []\n",
    "    for i,epoch in enumerate(df_tot_day['Epoch']):\n",
    "        if pd.isnull(epoch):\n",
    "            print(f'This value {epoch} is null. This is record number {i} in the file {path_rpa} or {path_nacs}')\n",
    "        else:\n",
    "            dat_list.append(pd.to_datetime(cdflib.cdfepoch.encode(epoch), infer_datetime_format=True))\n",
    "\n",
    "    d_t = pd.DatetimeIndex(dat_list)\n",
    "    df_tot_day['datetime'] = d_t\n",
    "    df_tot_day['year'] = d_t.year\n",
    "    df_tot_day['doy'] = d_t.dayofyear\n",
    "    df_tot_day['d_hr'] = d_t.hour + d_t.minute/60 + d_t.second/3600\n",
    "    return df_tot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "for rpa_path, nacs_path in zip(RPA_cdf_good, NACS_cdf_good):\n",
    "    df_tot_day = rpa_nacs_comb_day2(rpa_path, nacs_path, rpa_var_list, nacs_var_list)\n",
    "    df_all.append(df_tot_day, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ERR_RPA = df_make2(Path('C://Users/Ronald Maj/Sat_data/DE2/plasma_rpa/ion2s_cdaweb/1981/de2_ion2s_rpa_19810808_v01.cdf'),rpa_var_list)\n",
    "DF_ERR_NACS = df_make2(Path('C://Users/Ronald Maj/Sat_data/DE2/neutral_gas_nacs/neutral1s_nacs_cdaweb/1981/de2_neutral1s_nacs_19810808_v01.cdf'),nacs_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF_ERR_RPA.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ERR_NACS.iloc[9]['alt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nacs = DF_ERR_NACS\n",
    "df_rpa = DF_ERR_RPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "\n",
    "pn_ep = -5\n",
    "for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "    #print(r_ep)\n",
    "    for n_idx,n_ep in enumerate(df_nacs['Epoch']):\n",
    "        #print(n_ep)\n",
    "        if (r_ep == n_ep) and (r_ep != pn_ep):\n",
    "            #print(f'Here now! {r_ep} = {n_ep} I believe')\n",
    "            #print(f'This is the first value: {df_rpa.iloc[r_idx]}')\n",
    "            #print(f'This is the 2nd value: {df_nacs.iloc[n_idx]}')\n",
    "            RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "            NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "            pn_ep = n_ep\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACS_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df.head(5)['Epoch'][610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACS_df.head(5)['Epoch'][2398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df.head(5)['Epoch'][610] == NACS_df.head(5)['Epoch'][2398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One atomic mass unit in kilograms\n",
    "amukg = 1.66054e-27\n",
    "\n",
    "# Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "# Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "for idx in range(0,len(NACS_df)):\n",
    "    tot_den = 0.0\n",
    "    for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "        den = NACS_df.iloc[idx][var]\n",
    "        if np.isnan(den):\n",
    "            pass\n",
    "        else:\n",
    "            tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "    tot_den_nacs[idx] = tot_den\n",
    "try:\n",
    "    NACS_df['total_mass_den'] = tot_den_nacs\n",
    "except:\n",
    "    print(tot_den_nacs)\n",
    "# Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "# Total density of ions in kg.m^-3 for PRA instrument\n",
    "tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "for idx in range(0,len(RPA_df)):\n",
    "    tot_den = 0.0\n",
    "    for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "        den = RPA_df.iloc[idx][var]\n",
    "        if np.isnan(den):\n",
    "            pass\n",
    "        else:\n",
    "            tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "    tot_den_rpa[idx] = tot_den\n",
    "try:\n",
    "    RPA_df['total_mass_den'] = tot_den_rpa\n",
    "except:\n",
    "    print(tot_den_rpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_den_rpa[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_den_nacs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACS_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tot_den_nacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vars = ['Epoch']\n",
    "for el in nacs_var_list[6:9]:\n",
    "    pos_vars.append(el)\n",
    "pos_vars.append('total_mass_den')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_day = pd.DataFrame()\n",
    "\n",
    "for var in pos_vars:\n",
    "    print(var)\n",
    "    if var == 'total_mass_den':\n",
    "        #print(f'RPA length of values:{len(RPA_df[var].values)}')\n",
    "        #print(f'NACS values:{len(NACS_df[var].values)}')\n",
    "        df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values)\n",
    "        #print(df_tot_day[var])\n",
    "        df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "        df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "    else:\n",
    "        df_tot_day[var] = (RPA_df[var] + NACS_df[var]) / 2\n",
    "        print(len(df_tot_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa_var_list[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacs_var_list[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-07-03\n",
    "\n",
    "So the problem from yesterday was that (I think) there were cases where there were no measurements from any one of the species for a given instrument. In those cases the total mass density was not being recorded and the number of total mass densities was not equal to the number of epoch records.\n",
    "\n",
    "So now need to figure out how to fix that problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RPA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tot_den_rpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the length of the original dataframe is in fact 260, but when the new one is made, it is 520 - double.\n",
    "\n",
    "There must be a problem with double assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_day = pd.DataFrame()\n",
    "\n",
    "for var in pos_vars:\n",
    "    print(var)\n",
    "    if var == 'total_mass_den':\n",
    "        print(f'RPA length of values:{len(RPA_df[var].values)}')\n",
    "        print(f'NACS values:{len(NACS_df[var].values)}')\n",
    "        df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values)\n",
    "        print(df_tot_day[var])\n",
    "        df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "        df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "    else:\n",
    "        df_tot_day[var] = (RPA_df[var] + NACS_df[var]) / 2\n",
    "        print(len(df_tot_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RPA_df['alt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in pos_vars:\n",
    "    print(len(RPA_df[var].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_day = pd.DataFrame()\n",
    "print(len(df_tot_day))\n",
    "\n",
    "for var in pos_vars:\n",
    "    print(var)\n",
    "    print(len(RPA_df[var].values))\n",
    "    if var == 'total_mass_den':\n",
    "        print(f'RPA length of values:{len(RPA_df[var].values)}')\n",
    "        print(f'NACS values:{len(NACS_df[var].values)}')\n",
    "        df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values)\n",
    "        print(df_tot_day[var])\n",
    "        df_tot_day['total_neutral_den'] = NACS_df[var]\n",
    "        df_tot_day['total_ion_den'] = RPA_df[var]\n",
    "    else:\n",
    "        df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values) / 2\n",
    "        print(len(df_tot_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got it - it was the fact that the values were not being referenced. The dataframe assignment was creating an index value and because they did not match up, they were not being added together properly. Instead a new dataframe was created with the neutral and ion records separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "    for var in rpa_var_list[1:5]:\n",
    "        if var == 'O':\n",
    "            print(np.isnan(df_rpa.iloc[r_idx][var]))\n",
    "\n",
    "#df_rpa.iloc[1000]['O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_make2(path, vrs):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    # Round Epoch times to the nearest second:\n",
    "    epoch_round = lambda x: round(x/1000)*1000\n",
    "    df['Epoch'] = df['Epoch'].apply(epoch_round)\n",
    "    return df\n",
    "\n",
    "def rpa_nacs_comb_day2(path_rpa, path_nacs, vrs_rpa, vrs_nacs):\n",
    "    \n",
    "    # Make dfs:\n",
    "    df_rpa = df_make2(path_rpa, vrs_rpa)\n",
    "    df_nacs = df_make2(path_nacs, vrs_nacs)\n",
    "    \n",
    "    # Create dataframes to store only aligned records\n",
    "    # Find all aligned records and add them to new data frame:\n",
    "    \n",
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    pn_ep = -5\n",
    "    \n",
    "    for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "        if (not df_nacs[df_nacs['Epoch'] == r_ep].index.empty) and (r_ep != pn_ep):\n",
    "            n_idx = df_nacs[df_nacs['Epoch'] == r_ep].index[0]\n",
    "            rpa_nans = 0\n",
    "            nacs_nans = 0\n",
    "            for var_r in rpa_var_list[1:5]:\n",
    "                if np.isnan(df_rpa.iloc[r_idx][var_r]):\n",
    "                    rpa_nans += 1\n",
    "            for var_n in nacs_var_list[1:6]:\n",
    "                if np.isnan(df_nacs.iloc[n_idx][var_n]):\n",
    "                    nacs_nans += 1                    \n",
    "            if (rpa_nans == 4) or (nacs_nans == 5):\n",
    "                break\n",
    "            else:\n",
    "                RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "                NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "                pn_ep = n_ep\n",
    "                break\n",
    "    \n",
    "    # One atomic mass unit in kilograms\n",
    "    amukg = 1.66054e-27\n",
    "\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "    # Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "    tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "    for idx in range(0,len(NACS_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "            den = NACS_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "        tot_den_nacs[idx] = tot_den\n",
    "    try:\n",
    "        NACS_df['total_mass_den'] = tot_den_nacs\n",
    "    except:\n",
    "        print(NACS_df)\n",
    "        print(f'in the file {path_rpa} or {path_nacs}')\n",
    "        \n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "    # Total density of ions in kg.m^-3 for PRA instrument\n",
    "    tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "    for idx in range(0,len(RPA_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "            den = RPA_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "        tot_den_rpa[idx] = tot_den\n",
    "    try:\n",
    "        RPA_df['total_mass_den'] = tot_den_rpa\n",
    "    except:\n",
    "        print(tot_den_rpa)\n",
    "        \n",
    "    pos_vars = ['Epoch']\n",
    "    for el in nacs_var_list[6:9]:\n",
    "        pos_vars.append(el)\n",
    "    pos_vars.append('total_mass_den')\n",
    "\n",
    "    df_tot_day = pd.DataFrame()\n",
    "\n",
    "    for var in pos_vars:\n",
    "        if var == 'total_mass_den':\n",
    "            df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values)\n",
    "            df_tot_day['total_neutral_den'] = NACS_df[var].values\n",
    "            df_tot_day['total_ion_den'] = RPA_df[var].values\n",
    "        else:\n",
    "            df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values) / 2\n",
    "\n",
    "    # Convert glat and glon to radians:\n",
    "    df_tot_day['glat'] = df_tot_day['glat'] * (np.pi/180)\n",
    "    df_tot_day['glon'] = df_tot_day['glon'] * (np.pi/180)\n",
    "\n",
    "    dat_list = []\n",
    "    for i,epoch in enumerate(df_tot_day['Epoch']):\n",
    "        if pd.isnull(epoch):\n",
    "            print(f'This value {epoch} is null. This is record number {i} in the file {path_rpa} or {path_nacs}')\n",
    "        else:\n",
    "            dat_list.append(pd.to_datetime(cdflib.cdfepoch.encode(epoch), infer_datetime_format=True))\n",
    "\n",
    "    d_t = pd.DatetimeIndex(dat_list)\n",
    "    df_tot_day['datetime'] = d_t\n",
    "    df_tot_day['year'] = d_t.year\n",
    "    df_tot_day['doy'] = d_t.dayofyear\n",
    "    df_tot_day['d_hr'] = d_t.hour + d_t.minute/60 + d_t.second/3600\n",
    "    return df_tot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "for rpa_path, nacs_path in zip(RPA_cdf_good, NACS_cdf_good):\n",
    "    if RPA_cdf_good.index(rpa_path) < 100:\n",
    "        continue\n",
    "    else:\n",
    "        if RPA_cdf_good.index(rpa_path)%10 == 0:\n",
    "            print(f'Processing file {RPA_cdf_good.index(rpa_path)} of {len(RPA_cdf_good)}')\n",
    "        df_tot_day = rpa_nacs_comb_day2(rpa_path, nacs_path, rpa_var_list, nacs_var_list)\n",
    "        df_all = df_all.append(df_tot_day, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cdf_rpa = Path(Path.cwd(),'plasma_rpa/ion2s_cdaweb/1982/de2_ion2s_rpa_19820305_v01.cdf')\n",
    "err_cdf_nacs = Path(Path.cwd(),'neutral_gas_nacs/neutral1s_nacs_cdaweb/1982/de2_neutral1s_nacs_19820305_v01.cdf')\n",
    "\n",
    "df_rpa = df_make2(err_cdf_rpa, rpa_var_list)\n",
    "df_nacs = df_make2(err_cdf_nacs, nacs_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_rpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    pn_ep = -5\n",
    "    \n",
    "    for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "        if (not df_nacs[df_nacs['Epoch'] == r_ep].index.empty) and (r_ep != pn_ep):\n",
    "            n_idx = df_nacs[df_nacs['Epoch'] == r_ep].index[0]\n",
    "            rpa_nans = 0\n",
    "            nacs_nans = 0\n",
    "            for var_r in rpa_var_list[1:5]:\n",
    "                if np.isnan(df_rpa.iloc[r_idx][var_r]):\n",
    "                    rpa_nans += 1\n",
    "            for var_n in nacs_var_list[1:6]:\n",
    "                if np.isnan(df_nacs.iloc[n_idx][var_n]):\n",
    "                    nacs_nans += 1                    \n",
    "            if (rpa_nans == 4) or (nacs_nans == 5):\n",
    "                break\n",
    "            else:\n",
    "                RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "                NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "                pn_ep = n_ep\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_nacs['Epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df_rpa['Epoch']) - min(df_nacs['Epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference the maximum of rpa and minimum of nacs is positive, therefore there should be time that overlaps.\n",
    "\n",
    "### 2019-07-04\n",
    "\n",
    "Increased the speed of searching through the dataframe to find same time epoch yesterday, but now need to solve the new issue of the empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nacs[df_nacs['Epoch'] == r_ep].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpa.iloc[r_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpa[np.isnan(df_rpa['O'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire for-loop may be breaking because the first record doesn't have any ion measurement present.\n",
    "\n",
    "Therefore instead of 'break' need to have a 'continue' statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "\n",
    "pn_ep = -5\n",
    "\n",
    "for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "    if (not df_nacs[df_nacs['Epoch'] == r_ep].index.empty) and (r_ep != pn_ep):\n",
    "        n_idx = df_nacs[df_nacs['Epoch'] == r_ep].index[0]\n",
    "        rpa_nans = 0\n",
    "        nacs_nans = 0\n",
    "        for var_r in rpa_var_list[1:5]:\n",
    "            if np.isnan(df_rpa.iloc[r_idx][var_r]):\n",
    "                rpa_nans += 1\n",
    "        for var_n in nacs_var_list[1:6]:\n",
    "            if np.isnan(df_nacs.iloc[n_idx][var_n]):\n",
    "                nacs_nans += 1                    \n",
    "        if (rpa_nans == 4) or (nacs_nans == 5):\n",
    "            continue\n",
    "        else:\n",
    "            RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "            NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "            pn_ep = n_ep\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RPA_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that works, can re-run the files from before.\n",
    "\n",
    "The files will probably take longer to run now but there should be no prematurely finished files. At the moment the process of looking through the file would end after a case of no ion or no neutral densities was reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_make2(path, vrs):\n",
    "    # Open File\n",
    "    cdf = cdflib.CDF(path)\n",
    "    # Create a pandas dataframe from the data in the .cdf file:\n",
    "    data_arrs = [cdf.varget(variable = var) for var in vrs]\n",
    "    data_reshp = reshape_fn(data_arrs)\n",
    "    data = np.hstack(data_reshp)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Label columns\n",
    "    df.columns = vrs\n",
    "    # Convert any unreasonable values to NaN's and ensure all numbers are converted to floats\n",
    "    df[df < -1.000000e+30] = None\n",
    "    conv_float = lambda x: float(x)\n",
    "    df = df.applymap(conv_float)\n",
    "    # Round Epoch times to the nearest second:\n",
    "    epoch_round = lambda x: round(x/1000)*1000\n",
    "    df['Epoch'] = df['Epoch'].apply(epoch_round)\n",
    "    return df\n",
    "\n",
    "def rpa_nacs_comb_day2(path_rpa, path_nacs, vrs_rpa, vrs_nacs):\n",
    "    \n",
    "    # Make dfs:\n",
    "    df_rpa = df_make2(path_rpa, vrs_rpa)\n",
    "    df_nacs = df_make2(path_nacs, vrs_nacs)\n",
    "    \n",
    "    # Create dataframes to store only aligned records\n",
    "    # Find all aligned records and add them to new data frame:\n",
    "    \n",
    "    RPA_df = pd.DataFrame(columns=df_rpa.columns)\n",
    "    NACS_df = pd.DataFrame(columns=df_nacs.columns)\n",
    "    \n",
    "    pn_ep = -5\n",
    "    \n",
    "    for r_idx,r_ep in enumerate(df_rpa['Epoch']):\n",
    "        if (not df_nacs[df_nacs['Epoch'] == r_ep].index.empty) and (r_ep != pn_ep):\n",
    "            n_idx = df_nacs[df_nacs['Epoch'] == r_ep].index[0]\n",
    "            rpa_nans = 0\n",
    "            nacs_nans = 0\n",
    "            for var_r in rpa_var_list[1:5]:\n",
    "                if np.isnan(df_rpa.iloc[r_idx][var_r]):\n",
    "                    rpa_nans += 1\n",
    "            for var_n in nacs_var_list[1:6]:\n",
    "                if np.isnan(df_nacs.iloc[n_idx][var_n]):\n",
    "                    nacs_nans += 1                    \n",
    "            if (rpa_nans == 4) or (nacs_nans == 5):\n",
    "                continue\n",
    "            else:\n",
    "                RPA_df = RPA_df.append(df_rpa.iloc[r_idx])\n",
    "                NACS_df = NACS_df.append(df_nacs.iloc[n_idx])\n",
    "                pn_ep = df_nacs.iloc[n_idx]['Epoch']\n",
    "    \n",
    "    # One atomic mass unit in kilograms\n",
    "    amukg = 1.66054e-27\n",
    "\n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_nacs = [16,28,4,14,40]\n",
    "\n",
    "    # Total density of neutrals in kg.m^-3 for NACS instrument\n",
    "    tot_den_nacs = np.zeros((len(NACS_df),1))\n",
    "    for idx in range(0,len(NACS_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_nacs.columns[1:6]):\n",
    "            den = NACS_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += NACS_df.iloc[idx][var]*1e6*amus_nacs[i]*amukg\n",
    "        tot_den_nacs[idx] = tot_den\n",
    "    try:\n",
    "        NACS_df['total_mass_den'] = tot_den_nacs\n",
    "    except:\n",
    "        print(NACS_df)\n",
    "        print(f'in the file {path_rpa} or {path_nacs}')\n",
    "        \n",
    "    # Create a list of AMU for each atomic or molecular species in the var list we have:\n",
    "    amus_rpa = [16,1,4,30] # Molecular ion taken as the average of N2, O2 and NO (assuming equal proportions)\n",
    "\n",
    "    # Total density of ions in kg.m^-3 for PRA instrument\n",
    "    tot_den_rpa = np.zeros((len(RPA_df),1))\n",
    "    for idx in range(0,len(RPA_df)):\n",
    "        tot_den = 0.0\n",
    "        for i,var in enumerate(df_rpa.columns[1:5]):\n",
    "            den = RPA_df.iloc[idx][var]\n",
    "            if np.isnan(den):\n",
    "                pass\n",
    "            else:\n",
    "                tot_den += RPA_df.iloc[idx][var]*1e6*amus_rpa[i]*amukg\n",
    "        tot_den_rpa[idx] = tot_den\n",
    "    try:\n",
    "        RPA_df['total_mass_den'] = tot_den_rpa\n",
    "    except:\n",
    "        print(tot_den_rpa)\n",
    "        \n",
    "    pos_vars = ['Epoch']\n",
    "    for el in nacs_var_list[6:9]:\n",
    "        pos_vars.append(el)\n",
    "    pos_vars.append('total_mass_den')\n",
    "\n",
    "    df_tot_day = pd.DataFrame()\n",
    "\n",
    "    for var in pos_vars:\n",
    "        if var == 'total_mass_den':\n",
    "            df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values)\n",
    "            df_tot_day['total_neutral_den'] = NACS_df[var].values\n",
    "            df_tot_day['total_ion_den'] = RPA_df[var].values\n",
    "        else:\n",
    "            df_tot_day[var] = (RPA_df[var].values + NACS_df[var].values) / 2\n",
    "\n",
    "    # Convert glat and glon to radians:\n",
    "    df_tot_day['glat'] = df_tot_day['glat'] * (np.pi/180)\n",
    "    df_tot_day['glon'] = df_tot_day['glon'] * (np.pi/180)\n",
    "\n",
    "    dat_list = []\n",
    "    for i,epoch in enumerate(df_tot_day['Epoch']):\n",
    "        if pd.isnull(epoch):\n",
    "            print(f'This value {epoch} is null. This is record number {i} in the file {path_rpa} or {path_nacs}')\n",
    "        else:\n",
    "            dat_list.append(pd.to_datetime(cdflib.cdfepoch.encode(epoch), infer_datetime_format=True))\n",
    "\n",
    "    d_t = pd.DatetimeIndex(dat_list)\n",
    "    df_tot_day['datetime'] = d_t\n",
    "    df_tot_day['year'] = d_t.year\n",
    "    df_tot_day['doy'] = d_t.dayofyear\n",
    "    df_tot_day['d_hr'] = d_t.hour + d_t.minute/60 + d_t.second/3600\n",
    "    return df_tot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0 of 444\n",
      "Processing file 10 of 444\n",
      "Processing file 20 of 444\n",
      "Processing file 30 of 444\n",
      "Processing file 40 of 444\n",
      "Processing file 50 of 444\n",
      "Processing file 60 of 444\n",
      "Processing file 70 of 444\n",
      "Processing file 80 of 444\n",
      "Processing file 90 of 444\n",
      "Processing file 100 of 444\n",
      "Processing file 110 of 444\n",
      "Processing file 120 of 444\n",
      "Processing file 130 of 444\n",
      "Processing file 140 of 444\n",
      "Processing file 150 of 444\n",
      "Processing file 160 of 444\n",
      "Processing file 170 of 444\n",
      "Processing file 180 of 444\n",
      "Processing file 190 of 444\n",
      "Processing file 200 of 444\n",
      "Processing file 210 of 444\n",
      "Processing file 220 of 444\n",
      "Processing file 230 of 444\n",
      "Processing file 240 of 444\n",
      "Processing file 250 of 444\n",
      "Processing file 260 of 444\n",
      "Processing file 270 of 444\n",
      "Processing file 280 of 444\n",
      "Processing file 290 of 444\n",
      "Processing file 300 of 444\n",
      "Processing file 310 of 444\n",
      "Processing file 320 of 444\n",
      "Processing file 330 of 444\n",
      "Processing file 340 of 444\n",
      "Processing file 350 of 444\n",
      "Processing file 360 of 444\n",
      "Processing file 370 of 444\n",
      "Processing file 380 of 444\n",
      "Processing file 390 of 444\n",
      "Processing file 400 of 444\n",
      "Processing file 410 of 444\n",
      "Processing file 420 of 444\n",
      "Processing file 430 of 444\n",
      "Processing file 440 of 444\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "for rpa_path, nacs_path in zip(RPA_cdf_good, NACS_cdf_good):\n",
    "    if RPA_cdf_good.index(rpa_path)%10 == 0:\n",
    "        print(f'Processing file {RPA_cdf_good.index(rpa_path)} of {len(RPA_cdf_good)}')\n",
    "    df_tot_day = rpa_nacs_comb_day2(rpa_path, nacs_path, rpa_var_list, nacs_var_list)\n",
    "    df_all = df_all.append(df_tot_day, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.to_csv('All_Data_DE2_Ion_Neturals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465337"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
